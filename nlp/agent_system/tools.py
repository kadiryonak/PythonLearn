import os
from langchain_core.messages import HumanMessage, SystemMessage
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.tools import tool
import random

load_dotenv()

api_key = os.getenv("GROQ_API_KEY")

# Model
model = ChatGroq(
    api_key=api_key,
    model="llama-3.3-70b-versatile",
)



@tool
def get_weather(city: str) -> str:
    weather_data = {
        "istanbul": "Ä°stanbul: ParÃ§alÄ± bulutlu, 15Â°C",
        "ankara": "Ankara: GÃ¼neÅŸli, 12Â°C", 
        "izmir": "Ä°zmir: AÃ§Ä±k, 18Â°C",
        "kayseri": "Kayseri: KarlÄ±, -2Â°C",
    }
    city_lower = city.lower()
    return weather_data.get(city_lower, f"{city}: Hava bilgisi bulunamadÄ±")


@tool
def calculate(expression: str) -> str:
    try:
        result = eval(expression)
        return f"SonuÃ§: {result}"
    except Exception as e:
        return f"Hesaplama hatasÄ±: {str(e)}"


@tool
def roll_dice(sides: int = 6) -> str:
    result = random.randint(1, sides)
    return f"ğŸ² {sides} yÃ¼zlÃ¼ zar atÄ±ldÄ±: {result}"


tools = [get_weather, calculate, roll_dice]
model_with_tools = model.bind_tools(tools)


# Test 1: Hava durumu
print("\nğŸ“ Test 1: Hava Durumu")
response1 = model_with_tools.invoke([
    SystemMessage(content="Sen yardÄ±mcÄ± bir asistansÄ±n. Tool'larÄ± kullanarak sorularÄ± yanÄ±tla."),
    HumanMessage(content="Kayseri'de hava nasÄ±l?")
])
print(f"Model yanÄ±tÄ±: {response1.content}")
if response1.tool_calls:
    print(f"Tool Ã§aÄŸrÄ±sÄ±: {response1.tool_calls}")
    # Tool'u manuel Ã§alÄ±ÅŸtÄ±r
    for tool_call in response1.tool_calls:
        if tool_call['name'] == 'get_weather':
            result = get_weather.invoke(tool_call['args'])
            print(f"Tool sonucu: {result}")


# Test 2: Hesaplama
print("\nğŸ”¢ Test 2: Hesaplama")
response2 = model_with_tools.invoke([
    SystemMessage(content="Sen yardÄ±mcÄ± bir asistansÄ±n. Tool'larÄ± kullanarak sorularÄ± yanÄ±tla."),
    HumanMessage(content="125 * 48 kaÃ§ eder?")
])
print(f"Model yanÄ±tÄ±: {response2.content}")
if response2.tool_calls:
    print(f"Tool Ã§aÄŸrÄ±sÄ±: {response2.tool_calls}")
    for tool_call in response2.tool_calls:
        if tool_call['name'] == 'calculate':
            result = calculate.invoke(tool_call['args'])
            print(f"Tool sonucu: {result}")


# Test 3: Zar atma
print("\nğŸ² Test 3: Zar Atma")
response3 = model_with_tools.invoke([
    SystemMessage(content="Sen yardÄ±mcÄ± bir asistansÄ±n. Tool'larÄ± kullanarak sorularÄ± yanÄ±tla."),
    HumanMessage(content="20 yÃ¼zlÃ¼ bir zar at")
])
print(f"Model yanÄ±tÄ±: {response3.content}")
if response3.tool_calls:
    print(f"Tool Ã§aÄŸrÄ±sÄ±: {response3.tool_calls}")
    for tool_call in response3.tool_calls:
        if tool_call['name'] == 'roll_dice':
            result = roll_dice.invoke(tool_call['args'])
            print(f"Tool sonucu: {result}")

